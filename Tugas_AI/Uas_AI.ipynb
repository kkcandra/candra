{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkcandra/candra/blob/main/Tugas_AI/Uas_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menghubungkan Dengan google Dive, Ikutin Prosesnya sampai terhubung"
      ],
      "metadata": {
        "id": "do4p5bbxQGls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmVmHinnOhr6",
        "outputId": "e24979e5-5ead-4262-d31b-c1fec340adc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sesuakan Isi dari /content/drive/My Drive/Data_Uang Dengan Tempat Dimana menyimpan file dataset ( Data_Uang )"
      ],
      "metadata": {
        "id": "zWjLLbxSQSdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/Data_Uang'\n",
        "!ls \"/content/drive/My Drive/Data_Uang\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX8pLdKNQDPZ",
        "outputId": "b425883c-1cea-4776-ae99-becd821340d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bahan  train  validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Direktori Traning dan Validasi, dan membuat direktori seratus & limapuluh dalam direktori Traning dan Validasi"
      ],
      "metadata": {
        "id": "v2S3gTNaGGnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Menentukan Direktori\n",
        "\n",
        "# Tentukan nama direktori untuk latihan dan validasi\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Buat direktori latihan dan validasi beserta sub-direktorinya (seratus dan limapuluh)\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "\n",
        "train_seratus = os.path.join(train_dir, 'seratus')\n",
        "train_limapuluh = os.path.join(train_dir, 'limapuluh')\n",
        "validation_seratus = os.path.join(validation_dir, 'seratus')\n",
        "validation_limapuluh = os.path.join(validation_dir, 'limapuluh')\n",
        "\n",
        "os.makedirs(train_seratus, exist_ok=True)\n",
        "os.makedirs(train_limapuluh, exist_ok=True)\n",
        "os.makedirs(validation_seratus, exist_ok=True)\n",
        "os.makedirs(validation_limapuluh, exist_ok=True)\n",
        "\n",
        "# Cek apakah direktori telah berhasil dibuat\n",
        "print(\"Direktori latihan dan validasi telah dibuat:\")\n",
        "print(\"Train Directory:\", train_dir)\n",
        "print(\"Validation Directory:\", validation_dir)"
      ],
      "metadata": {
        "id": "MYEnI_MQQgTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menyiapkan Dataset, Mengisi Folder Traning dan Validasi dengan data yang ada di dalam Folder Bahan dan melakukan Shuffling data dengan rasio pembagi 90 % data Traning 10 % data Validasi"
      ],
      "metadata": {
        "id": "xl4-4kygTRK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "# Mendefinisikan path ke folder 'Data_Uang'\n",
        "data_uang_dir = base_dir   # Ganti dengan path yang sesuai\n",
        "\n",
        "# Memeriksa apakah folder 'Data_Uang' ada\n",
        "if not os.path.exists(data_uang_dir):\n",
        "    print(\"Folder 'Data_Uang' tidak ditemukan.\")\n",
        "    exit()\n",
        "\n",
        "# Mendefinisikan path untuk folder 'bahan'\n",
        "bahan_dir = os.path.join(data_uang_dir, 'bahan')\n",
        "\n",
        "# Memeriksa apakah folder 'bahan' ada di dalam folder 'Data_Uang'\n",
        "if not os.path.exists(bahan_dir):\n",
        "    print(\"Folder 'bahan' tidak ditemukan di dalam folder 'Data_Uang'.\")\n",
        "    exit()\n",
        "\n",
        "# Mendefinisikan path untuk folder 'seratus' dan 'limapuluh' di dalam folder 'bahan'\n",
        "seratus_dir = os.path.join(bahan_dir, 'seratus')\n",
        "limapuluh_dir = os.path.join(bahan_dir, 'limapuluh')\n",
        "\n",
        "# Memeriksa apakah folder 'seratus' dan 'limapuluh' ada di dalam folder 'bahan'\n",
        "if not os.path.exists(seratus_dir) or not os.path.exists(limapuluh_dir):\n",
        "    print(\"Folder 'seratus' atau 'limapuluh' tidak ditemukan di dalam folder 'bahan'.\")\n",
        "    exit()\n",
        "\n",
        "def train_val_split(source, train, val, train_ratio):\n",
        "    # Membuat direktori jika tidak ada\n",
        "    if not os.path.exists(train):\n",
        "        os.makedirs(train)\n",
        "    if not os.path.exists(val):\n",
        "        os.makedirs(val)\n",
        "\n",
        "    total_size = len(os.listdir(source))\n",
        "    train_size = int(train_ratio * total_size)\n",
        "    val_size = total_size - train_size\n",
        "\n",
        "    randomized = random.sample(os.listdir(source), total_size)\n",
        "    train_files = randomized[0:train_size]\n",
        "    val_files = randomized[train_size:total_size]\n",
        "\n",
        "    for i in train_files:\n",
        "        i_file = os.path.join(source, i)\n",
        "        destination = os.path.join(train, i)\n",
        "        copyfile(i_file, destination)\n",
        "\n",
        "    for i in val_files:\n",
        "        i_file = os.path.join(source, i)\n",
        "        destination = os.path.join(val, i)\n",
        "        copyfile(i_file, destination)\n",
        "\n",
        "# Pembagian Traning dan Validasi\n",
        "# Traning 100k\n",
        "source_00 = seratus_dir\n",
        "train_00 = train_seratus\n",
        "val_00 = validation_seratus\n",
        "train_ratio = 0.9  # Misalkan 90% data untuk training\n",
        "train_val_split(source_00, train_00, val_00, train_ratio)\n",
        "\n",
        "# Traning 50K\n",
        "source_01 = limapuluh_dir\n",
        "train_01 = train_limapuluh\n",
        "val_01 = validation_limapuluh\n",
        "train_val_split(source_01, train_01, val_01, train_ratio)\n"
      ],
      "metadata": {
        "id": "VGlT2O5kTTXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengecek Kembali Apakah jumlah data sudah terisi dengan benar"
      ],
      "metadata": {
        "id": "J3HiFViqMKHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Jumlah All seratus :', len(os.listdir(source_00)))\n",
        "print('Jumlah Train seratus :', len(os.listdir(train_seratus)))\n",
        "print('Jumlah Val seratus :', len(os.listdir(validation_seratus)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zppvgGhdWjgs",
        "outputId": "6093a87c-d5c6-41ad-c7d5-29cdc30c284b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah All seratus : 100\n",
            "Jumlah Train seratus : 90\n",
            "Jumlah Val seratus : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Pre Processing Menggunakan Tensorflo dengan optimizer Adam dan image data generator, digunakan untuk melatih kondisi data\n",
        "dimana membuat data dengan rescale 1./255 untuk mengenali picxel terkecil, rotasi ketika gambar dalam bentuk miring, filip ketika gambar terbalik dan seterusnya"
      ],
      "metadata": {
        "id": "G3mmrWt6MhyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "wXd4BUtEXAro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                rescale = 1./255,\n",
        "                rotation_range = 30,\n",
        "                horizontal_flip = True,\n",
        "                shear_range = 0.3,\n",
        "                fill_mode = 'nearest',\n",
        "                width_shift_range = 0.2,\n",
        "                height_shift_range = 0.2,\n",
        "                zoom_range = 0.1\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "                rescale = 1./255,\n",
        "                rotation_range = 30,\n",
        "                horizontal_flip = True,\n",
        "                shear_range = 0.3,\n",
        "                fill_mode = 'nearest',\n",
        "                width_shift_range = 0.2,\n",
        "                height_shift_range = 0.2,\n",
        "                zoom_range = 0.1\n",
        ")"
      ],
      "metadata": {
        "id": "kIyqP5vhXRez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menentukan Targent Dimana Kami menggunakan target size 150, 150 dengan batch size 10, hasil terbagi menjadi 2 kelas yang di atas adalah data dari traning dan yang di bawah untuk hasil data validasi"
      ],
      "metadata": {
        "id": "_366OkcJNL5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size = (150, 150),\n",
        "      batch_size = 10,\n",
        "      class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size = (150, 150),\n",
        "      batch_size = 10,\n",
        "      class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "F7cUJJd4YHKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callback dengan batasan 99% ketika data sudah diperoses dan menghasilkan akurasi 99%, meskipun iterasi masih berjalan maka pemprosesan akan berhenti"
      ],
      "metadata": {
        "id": "l8kB6AFGNujO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if(logs.get('accuracy') > 0.99):\n",
        "      print('\\n Akurasi Mencapai 99%')\n",
        "      self.model.stop_traning = True\n",
        "\n",
        "checkpoint = myCallback()"
      ],
      "metadata": {
        "id": "aQH94X8kYrdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model CNN"
      ],
      "metadata": {
        "id": "hEjsrXs6ZeoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (150, 150, 3)),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(200, activation = 'relu'),\n",
        "            tf.keras.layers.Dropout(0.3,seed=112),\n",
        "            tf.keras.layers.Dense(500, activation = 'relu'),\n",
        "            tf.keras.layers.Dropout(0.5,seed=112),\n",
        "            tf.keras.layers.Dense(2, activation = 'sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "KvtVlO__ZeTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5YXtGMB7azUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6YCczTvHa1wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch = 6,\n",
        "            epochs = 25,\n",
        "            validation_data = val_generator,\n",
        "            validation_steps = 1,\n",
        "            verbose = 1,\n",
        "            callbacks=[checkpoint]\n",
        "            )\n",
        "\n"
      ],
      "metadata": {
        "id": "Hfh8CEpYTCiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tingkat Akurasi Dan Loos Model"
      ],
      "metadata": {
        "id": "LnKmgkaggkwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_los = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label = 'Traning Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation Accoracy')\n",
        "plt.title('Traning And Valifation Accuracy')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "79N9ywW-gj88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coba Kalsifikasi"
      ],
      "metadata": {
        "id": "EoMPFYEPh_0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt  # Anda harus mengimpor pyplot\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    path = fn\n",
        "\n",
        "    # Prediksi Gambar\n",
        "    img = image.load_img(path, target_size=(150, 150))\n",
        "    imgplot = plt.imshow(img)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=100)\n",
        "\n",
        "    print(fn)\n",
        "\n",
        "    class_list = os.listdir(train_dir)\n",
        "\n",
        "    for j in range(42):\n",
        "        if classes[0][j] == 1.:\n",
        "            print(' Gambar Ini ', class_list[j-1])\n",
        "            break\n"
      ],
      "metadata": {
        "id": "yVEaSjPMh740"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}